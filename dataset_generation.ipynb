{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fac0c21",
   "metadata": {},
   "source": [
    "# Spotify Songs Network - Dataset Generation\n",
    "* In this notebook we will create the dataset that we will use to create a Network about Spotify Songs, based on user's Playlists.\n",
    "* Specifically, we want to create a Network with the following characteristics\n",
    "  * **Nodes**: Songs\n",
    "  * **Edges**: will be created between songs if the songs are found in the same playlist.\n",
    "* In this notebook, we will create our dataset, and to do that we will obtain data from:\n",
    "  1. [Spotify Playlists](https://www.kaggle.com/andrewmvd/spotify-playlists) Dataset from [Kaggle](https://www.kaggle.com/).\n",
    "    * Pichl, Martin; Zangerle, Eva; Specht, GÃ¼nther: \"Towards a Context-Aware Music Recommendation Approach: What is Hidden in the Playlist Name?\" in 15th IEEE International Conference on Data Mining Workshops (ICDM 2015), pp. 1360-1365, IEEE, Atlantic City, 2015.\n",
    "    * **License**: CC BY 4.0\n",
    "  2. [Spotify Web API](https://developer.spotify.com/documentation/web-api/)\n",
    "  3. [Chosic Music Genre Finder](https://www.chosic.com/music-genre-finder/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c034c4e",
   "metadata": {},
   "source": [
    "## Spotify for Developers Credentials\n",
    "* In case a user of this notebook wants to execute the cells that create a connection with the [Spotify's Web API](https://developer.spotify.com/documentation/web-api/) it is necessary to create an application at http://developer.spotify.com.\n",
    "* In that way the user will get a client ID and a client secret.\n",
    "* Then, they have to create a file `spotify_config.py` with the following contents:\n",
    "\n",
    "  ```\n",
    "  config = {\n",
    "      'client_id' : 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX',\n",
    "      'client_secret' :'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "  }\n",
    "  ```\n",
    "  where instead of Xs there are the client ID and client secret of the user.\n",
    "* This file will be placed in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a344fb",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "* To begin with, we will import the packages, that we will use in the following segments of the project:\n",
    "    * [pandas](https://pandas.pydata.org/)\n",
    "    * [Spotipy](https://spotipy.readthedocs.io/en/2.19.0/)\n",
    "    * [webdriver-manager](https://pypi.org/project/webdriver-manager/)\n",
    "    * [Selenium](https://selenium-python.readthedocs.io/)\n",
    "    * [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/)\n",
    "* Note that the prementioned packages **must be locally installed too** in order to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b44835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "\n",
    "import random\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037102b7",
   "metadata": {},
   "source": [
    "## Kaggle Dataset\n",
    "* As mentioned above, we will get the basic data from [Spotify Playlists](https://www.kaggle.com/andrewmvd/spotify-playlists) Dataset from [Kaggle](https://www.kaggle.com/).\n",
    "* After downloading it, we have to create a folder <code>data</code> and put it into it, under the name <code>spotify_dataset.csv.zip</code>.\n",
    "* So, let's read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef239c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>\"artistname\"</th>\n",
       "      <th>\"trackname\"</th>\n",
       "      <th>\"playlistname\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Elvis Costello</td>\n",
       "      <td>(The Angels Wanna Wear My) Red Shoes</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Elvis Costello &amp; The Attractions</td>\n",
       "      <td>(What's So Funny 'Bout) Peace, Love And Unders...</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Tiffany Page</td>\n",
       "      <td>7 Years Too Late</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Elvis Costello &amp; The Attractions</td>\n",
       "      <td>Accidents Will Happen</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Elvis Costello</td>\n",
       "      <td>Alison</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id                      \"artistname\"  \\\n",
       "0  9cc0cfd4d7d7885102480dd99e7a90d6                    Elvis Costello   \n",
       "1  9cc0cfd4d7d7885102480dd99e7a90d6  Elvis Costello & The Attractions   \n",
       "2  9cc0cfd4d7d7885102480dd99e7a90d6                      Tiffany Page   \n",
       "3  9cc0cfd4d7d7885102480dd99e7a90d6  Elvis Costello & The Attractions   \n",
       "4  9cc0cfd4d7d7885102480dd99e7a90d6                    Elvis Costello   \n",
       "\n",
       "                                         \"trackname\"  \"playlistname\"  \n",
       "0               (The Angels Wanna Wear My) Red Shoes  HARD ROCK 2010  \n",
       "1  (What's So Funny 'Bout) Peace, Love And Unders...  HARD ROCK 2010  \n",
       "2                                   7 Years Too Late  HARD ROCK 2010  \n",
       "3                              Accidents Will Happen  HARD ROCK 2010  \n",
       "4                                             Alison  HARD ROCK 2010  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/spotify_dataset.csv.zip', on_bad_lines='skip')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014412d",
   "metadata": {},
   "source": [
    "* Next, we will rename the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={' \"artistname\"' : 'Artist', ' \"trackname\"': 'Track_Name', ' \"playlistname\"': 'Playlist_Name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073c763",
   "metadata": {},
   "source": [
    "* Because our dataset contains too many songs we will **keep** only those that are included in more than 500 playlists.\n",
    "* We will do that because if we have to many nodes in our Network, it will not be easily **interpretable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/44888858/how-to-drop-unique-rows-in-a-pandas-dataframe\n",
    "df = df[df.groupby(['Track_Name', 'Artist'])['Track_Name'].transform('size') > 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c515601",
   "metadata": {},
   "source": [
    "* Also, we will combine the columns <code>user_id</code> and <code>Playlist_Name</code> into one, in order to be our data more concentrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865dfdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Playlist'] = df.apply(lambda row: str(row['Playlist_Name']) + \" by \" + row['user_id'], axis=1)\n",
    "df.drop(columns=['user_id', 'Playlist_Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b765dc",
   "metadata": {},
   "source": [
    "## Edges Creation\n",
    "* Next, we will create our edges, that will be **weighted**.\n",
    "* Each edge will have a *Source*, a *Target* and a *Weight*.\n",
    "* The *Weight* will be the number of Playlists that the two songs are included together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c720c4",
   "metadata": {},
   "source": [
    "* Before doing that, some songs contain in their names characters that make them not searchable using the API, so we will slightly modify their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_name_mapping = {\n",
    "    \"Baba O'Riley - Original Album Version\" : \"Baba O'Riley\",\n",
    "    'Jerk It Out - Original Mix' : 'Jerk It Out',\n",
    "    'Jump - Remastered Version' : 'Jump',\n",
    "    \"Don't You Worry Child (Radio Edit) [feat. John Martin]\" : \"Don't You Worry Child Radio Edit\",\n",
    "    'Save the World - Radio Mix' : 'Save the World',\n",
    "    'Wildfire (feat. Little Dragon)' : 'Wildfire',\n",
    "    'Blister In The Sun (Remastered Album Version)' : 'Blister In The Sun',\n",
    "    'Hey Ya! - Radio Mix / Club Mix' : 'Hey Ya!',\n",
    "    'How Soon Is Now? (2008 Remastered Version)' : 'How Soon Is Now?',\n",
    "    'Intergalactic - 2009 Digital Remaster' : 'Intergalactic',\n",
    "    'This Charming Man (2008 Remastered Version)' : 'This Charming Man',\n",
    "    'Suit & Tie featuring JAY Z' : 'Suit & Tie',\n",
    "    'A-Punk (Album)' : 'A-Punk',\n",
    "    'Heroes - 1999 Remastered Version' : 'Heroes',\n",
    "    'Sexy Bitch (feat. Akon) - Featuring Akon;explicit' : 'Sexy Bitch',\n",
    "    'Wannabe - Radio Edit' : 'Wannabe'    \n",
    "}\n",
    "\n",
    "df['Track_Name'] = df['Track_Name'].map(lambda x: track_name_mapping.get(x, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ffcb34",
   "metadata": {},
   "source": [
    "* Now, we are ready to create the nodes of our Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf35a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = df[['Track_Name', 'Artist']].copy().drop_duplicates()\n",
    "nodes.reset_index(inplace=True, drop=True)\n",
    "nodes['Id'] = nodes.index\n",
    "nodes.rename(columns={'Track_Name': 'Label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498af644",
   "metadata": {},
   "source": [
    "* Then, we will create a new column into the datast, that will contain the *Node ID* for each track.\n",
    "* To do that, we will use a mapping, with keys the name of the track and the artist and values the id of the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448c85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tracks_artist = list(zip(nodes['Label'], nodes['Artist']))\n",
    "nodes_id_mapping = dict(zip(list_tracks_artist, nodes['Id']))\n",
    "\n",
    "df['Track_Id'] = df.apply(lambda row: nodes_id_mapping[(row['Track_Name'], row['Artist'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072811b6",
   "metadata": {},
   "source": [
    "* The next thing we will do is to count the number of playlists that each pair of tracks are included together.\n",
    "* To do that, first we will **group** our dataframe using the <code>Playlist</code> column.\n",
    "* And then, we will use [itertools](https://docs.python.org/3/library/itertools.html#itertools) to get all the possible pairs within each playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby('Playlist')\n",
    "\n",
    "pair_counts = defaultdict(int)\n",
    "for name, group in df_grouped:\n",
    "    try:\n",
    "        pairs = list(combinations(group['Track_Id'], 2))\n",
    "        for pair in pairs:\n",
    "            pair_sorted = tuple(sorted(list(pair)))\n",
    "            pair_counts[pair_sorted] += 1\n",
    "    except MemoryError:\n",
    "        print('Group {} is too big, it contains {} rows.'.format(name, len(group)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31f3ee",
   "metadata": {},
   "source": [
    "* We are now ready to extract our edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_headers(writer):\n",
    "    headers = ['Source', 'Target', 'Weight']\n",
    "    writer.writerow(headers)\n",
    "\n",
    "def write_edges(writer, edges_weights_dict):\n",
    "    for edge in edges_weights_dict.keys():\n",
    "        edge_row = [edge[0], edge[1], edges_weights_dict[edge]]\n",
    "        writer.writerow(edge_row)\n",
    "\n",
    "f = open('network_data/edges.csv', 'w', newline='')\n",
    "writer = csv.writer(f)\n",
    "\n",
    "write_headers(writer)\n",
    "write_edges(writer, pair_counts)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec326d",
   "metadata": {},
   "source": [
    "## Spotify Web API\n",
    "* Unfortunately, our main dataset does not contain any **extra information** about the songs, except their name and artist.\n",
    "* So we will try to enrich our dataset by using the [Spotify Web API](https://developer.spotify.com/documentation/web-api/).\n",
    "* We don't even have the Spotify ID of each song, so we have to **search** for it, using the name of the song and the artist.\n",
    "* *Remember, to create a connection with Spotify's API using the following code a <code>spotify_config.py</code> file must have been created as mentioned in the beginning*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a995e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotify_config import config\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(config['client_id'],\n",
    "                                                      config['client_secret'])\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f29f14",
   "metadata": {},
   "source": [
    "* Next, for each node of our network we will get the *audio features* that Spotify provides.\n",
    "* The following code searches using the API using the name and artist for each song, in order to get its id in Spotify. Then, the audio features of the songs are gotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c8269af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from 0 to 100\n",
      "getting from 100 to 200\n",
      "getting from 200 to 300\n",
      "getting from 300 to 400\n",
      "getting from 400 to 500\n",
      "getting from 500 to 600\n",
      "getting from 600 to 700\n",
      "getting from 700 to 800\n",
      "getting from 800 to 900\n",
      "getting from 900 to 1000\n"
     ]
    }
   ],
   "source": [
    "nodes['Track'] = nodes.apply(lambda row: row['Label'] + \" \" + row['Artist'], axis=1)\n",
    "\n",
    "ids = list(nodes['Id'])\n",
    "tracks = list(nodes['Track'])\n",
    "\n",
    "def get_track_id_from_json(track_json):\n",
    "    return track_json['tracks']['items'][0]['uri']\n",
    "\n",
    "features = {}\n",
    "start = 0\n",
    "num_tracks = 100\n",
    "while start < len(ids):\n",
    "    print(f'getting from {start} to {start+num_tracks}')\n",
    "    ids_batch = ids[start:start+num_tracks]\n",
    "    tracks_batch = tracks[start:start+num_tracks]\n",
    "    spotify_ids_batch = []\n",
    "    for track in tracks_batch:\n",
    "        try:\n",
    "            search_result = sp.search(q=track, type='track', limit=1)\n",
    "            spotify_ids_batch.append(get_track_id_from_json(search_result))\n",
    "        except:\n",
    "            print(track)\n",
    "    features_batch = sp.audio_features(spotify_ids_batch)\n",
    "    features.update({ id : track_features \n",
    "                     for id, track_features in zip(ids_batch, features_batch) })\n",
    "    start += num_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af8f637",
   "metadata": {},
   "source": [
    "* Let's put them into a dataframe.features_df = pd.DataFrame.from_dict(features, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "88b53ac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.439</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-17.227</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.01480</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.551</td>\n",
       "      <td>81.833</td>\n",
       "      <td>236933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.548</td>\n",
       "      <td>-7.103</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.35100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.750</td>\n",
       "      <td>121.942</td>\n",
       "      <td>214920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.284</td>\n",
       "      <td>0.875</td>\n",
       "      <td>-6.069</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.00752</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>0.595</td>\n",
       "      <td>75.009</td>\n",
       "      <td>340907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.360</td>\n",
       "      <td>0.684</td>\n",
       "      <td>-6.457</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.32300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.200</td>\n",
       "      <td>77.150</td>\n",
       "      <td>342653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.270</td>\n",
       "      <td>0.944</td>\n",
       "      <td>-4.199</td>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.00501</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>0.606</td>\n",
       "      <td>146.347</td>\n",
       "      <td>269920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Danceability  Energy  Loudness  Speechiness  Acousticness  \\\n",
       "0         0.439   0.422   -17.227       0.0409       0.01480   \n",
       "1         0.803   0.548    -7.103       0.1200       0.35100   \n",
       "2         0.284   0.875    -6.069       0.0422       0.00752   \n",
       "3         0.360   0.684    -6.457       0.0308       0.32300   \n",
       "4         0.270   0.944    -4.199       0.0975       0.00501   \n",
       "\n",
       "   Instrumentalness  Liveness  Valence    Tempo  Duration_ms  \n",
       "0          0.000048    0.0697    0.551   81.833       236933  \n",
       "1          0.000000    0.0953    0.750  121.942       214920  \n",
       "2          0.000461    0.4020    0.595   75.009       340907  \n",
       "3          0.000000    0.3400    0.200   77.150       342653  \n",
       "4          0.000021    0.1160    0.606  146.347       269920  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.DataFrame.from_dict(features, orient='index')\n",
    "features_df.drop(columns=['key', 'mode', 'type', 'id', 'uri', 'track_href', 'analysis_url', 'time_signature'], inplace=True)\n",
    "features_df.columns = features_df.columns.to_series().apply(lambda name: name.capitalize())\n",
    "features_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
